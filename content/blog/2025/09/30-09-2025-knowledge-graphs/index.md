---
title: "Knowledge graphs for networking"
date: 2025-10-30T10:00:00+00:00
image: images/blog/graphops_header.png
og_image: images/og-default.png
author: David Gee
description: "Now is the time for knowledge graphs for networking!"
signoff: Dave
mermaid: false
categories:
- graphops
- graph
- knowledgegraphs
tags:
- business
- networking
- knowledgegraphs
- graphops
- graph
- networking
---

Knowledge graphs offer a multi-dimensional set of projected views and methods of managing cross-team, meaningful data for any business.<!--more-->The possibilities are near limitless for the management of information and infrastructure. Knowledge graphs cover configuration state, desired state and operational state, which goes way beyond the current tool-based approach. I want to suggest, the whole premise of knowledge graphs is an entire reshape of the current automation landscape, but there is a question of real world value, over nerd-value, which by the way, is off the charts! I'm pleased that people like Damien Garros are moving this field along with the [OpsMill InfraHub](https://opsmill.com/how-infrahub-compares/) product and I about fell off my comfy office chair when reading about the [Hashicorp InfraGraph announcement](https://newsroom.ibm.com/2025-09-25-hashicorp-previews-the-future-of-agentic-infrastructure-automation-with-project-infragraph). Finally, a sense that timing is right for this much-needed and extremely interesting next era of automation. If you're reading this, I must mention that I'm talking about this at a high level and if you were attempting to build one, some of the points in this article will be moot for those using products, but good info nevertheless. Productised knowledge graphs naturally will demand less of the operator than creating one from the ground up, but whatever track you follow, everything that follows suggests a non-trivial amount of work, time and knowledge to do it justice. 

Before you go out looking for a knowledge graph, it's worth stating that you're probably not going to find a fully complete off-the-shelf system just yet. Knowledge graphs as of 2025 will be driven by a skilled developer with a computer science background in partnership with a network engineer. This is where I believe the partnership between both sides delivers actual fruit. Business-wide, the effects should be felt deeply and widely.

If you've adopted some network automation, then you have invested time into tools that exist and I'm not advocating for their removal, unless going full green field. A knowledge graph approach sits adjacent to your skill sets and existing tooling, turning you into a systems engineer instead of tools operator. NetBox and Ansible are great examples of this. These components are in daily use with thousands of hours of developer and support experience racked up. Standing on the shoulders of giants is a must when approaching these fun but gnarly evolutional leaps.

# Elephant in the room

The cult of network automation is guilty at large of being hyper-focussed on the individual power tools of the trade. Without trying to hide it, I get a bit Clint Eastwood-y when hearing a certain conversation come up, having heard the arguments and have taken part in them for well over a decade. Me being a bit of a grump about it is backed up by this podcast which was recorded with Mr Pepelnjak in September 2025. The focus on tooling is derived from the classic network engineering mindset, in which engineers are ordained into a world of interesting protocols with plenty of knobs to control them, classically exposed through the command-line interface of some network operating system (NOS). It's no surprise then that the target of the current automation effort for engineers is to generate CLI configuration and ~~slap~~ commit it to a device. Humans have done a great job of getting this far as networks explode in number and complexity, and I salute anyone that has built, deployed and operated a production network, and genuinely so. I still stand in awe of network engineers that obtain their CCIE and JNCIE numbers, so please understand me when I say I'm not poking fun or making arbitrary judgements. This level of skill is about as deep as it gets, beyond writing the protocol algorithms. I am a practitioner, researcher and lifelong automation person, having invested an inordinate pile of money and time into going as deep and as wide as I can in this field. In that journey, I have gone as far as obtaining all the usual certificates, like Cisco CCNA, CCNP, CCVP, CCSP, CCIP, JNCIA, JNCIS, JNCIP and an endless list of other accreditations like F5, Radware, HP SDN, IPv6 Gold and the dreaded OpenStack RHCSA. At each point of the journey, I went beyond the professional level but backed away at vendor expert level because that was not my goal. Each accreditation was fought and battled for, and the knowledge was put to good use in my career at different points, but the most important takeaway here is I've put the time in to understand what a network is, how data flows and how networks should be built, across campus, data centre and ISP disciplines, having run my own ASN delivering content for well-known household brands. Been there, done that, got the scars and wardrobes of worn shirts.

Now that you trust me, let's go back to the top and breathe in a bit. Reasons to automate vary immensely, but commonly centre on removing humans from the loop, to speed things up, reduce errors and reduce humans entirely. The result is fewer jobs, but with higher levels of responsibility for the remaining practitioners. To square the view up, we also need to consider the what of automation with the question of "what are we trying to accomplish?" and not just high level objectives. That might be connecting cloud services to a corporate campus or extension of the data centre, or something as simple as adding a VLAN and configuring access ports. If we're serious about automation, then ***day one*** will also be included, bootstrapping each device from the ground up to include baseline configuration inputs, like NTP, DNS, Syslog and modern telemetry configuration. This aspect means a device can easily be replaced without doing config restores. You never know what software updates do, and being able to yield interesting state errors is part of the fun! I'll call out here too that day zero, day one and day two are in the eye of the beholder. Everything in this post is on the topic of knowledge graphs and not opinions on semi-flexible rails.

# Horizontal and vertical abstraction

Before talking about knowledge graphs, we must also discuss abstraction, because that has some influence on the shape of the knowledge graph and data structures. When we're dealing with tools like Ansible or Terraform, I'll describe them as horizontal integration and a first-order actuator. Horizontal because the tools perform deterministic tasks with templatised configuration and in the same parlance, first-order because the input data directly affects the output data, and it can be reasoned about without guessing at black-box style behaviours. These tools take some baseline data (variables and templates in the case of Ansible) and project that data via an interaction protocol to the network device. In this manner, we've not really done a whole lot of abstraction at the tool level and it's kind of a phony, config-centric model. For the remainder of this post I'll talk about Ansible when referring to automation tools to keep the conversation simple because it's simple and prolific in use. Horizontal abstraction tools like Ansible offer simple composition (i.e., playbooks), which, in addition to delivering batched changes, gives us an impression that we're somehow working with a model, even though its a configuration model with light implicit referentiality, driven by variable interpolation. I consider these tools part of a bigger picture and not the end of the journey, nor are they close to the promise of knowledge graphs. My reasoning is that the model in this form is some templates and variable data, that when interpolated, generates device configuration. There is a vague notion of model configurations that, when blasted with data, look like configurations that might be accepted by some NOS. So to protect against this fragility, what do we do? Chuck some CI/CD at it and if the tests pass, we're done. Ok, I'm being cruel and intentionally so. Take Arista's AVD approach. This alone can tremendously speed up deployment and reduce errors, but to repeat myself, we're a way off from the whispered flirtations of knowledge graphs. I might have mentioned at the beginning of this post, network automation has been a major theme for my career to date, and I aim to improve and elevate what we consider possible.

Regarding data referentiality, I never cease to be amazed that building and deploying multiple configurations in parallel actually delivers meaningful changes to the network, as well as whole configuration replacement operations. My amazement stems from the fact that data referentiality is driven by an engineer creating a data structure, or some interface that automates the creation of the data structure in text-based form, out of the control loop of the software. I.e., open up a text editor, create some stuff and let's keep tapping it with a small hammer until it works. This kind of work is the hallmark of a skilled engineering team, but it has a huge set of assumed knowledge. Some off-the-shelf products work this way too, but they're rarely as flexible and constrained by an epic amount of code to limit the possible dangers, damage and risk. Second point to this paragraph is that a full config replacement, passes the buck to the network operating system, to create a diff (from receiving the full config) and patch the configuration store onboard. Submitting patch changes to the NOS feels nicer in this regard and that's what Terraform for Junos does; it creates a small config change and commits it via a candidate Junos configuration.

The terms vertical and horizontal abstraction are terms that I use in general automation conversations, but you might not find them in automation literature, so next I will introduce vertical abstraction. It is the principle of building relationships between the device and baseline data *(what am I? What NTP servers do I use?)*, and service data *(what am I supposed to do?)* in graph form. Some of the loose relationships might be different, i.e, the horizontal tools might be the only systems making changes to the network devices, but this hopefully helps.

{{<imgcenterlink href="" src="vertical_horizontal.png" alt="Vertical vs Horizontal">}}<br/>

Vertical abstraction extends the data integrity and control loop down to the device interaction protocol, whilst also offering time-travel capabilities with partial or full graph history. The shape of the data is important for the graph, and as such, controls can be put in place at a shape agnostic level. Some would call this being vendor agnostic, but we could be describing the history of the East India Company. Changes can be replayed at the device scope, or across a blast radius of devices scoped at the service level, in the order they were made. This concept leads us down the configuration-sourcing path, where a single device's desired state can be iteratively patched to meet current requirements through diffs. Imagine placing arbitrary data based on a region, data centre or cupboard location, then creating an arbitrary service—say a VXLAN segment for a data centre—and attaching access ports. At a very high level, the relationships might look like this for configuration inheritance, though this model doesn't capture the full service view.

{{<imgcenterlink href="" src="k_graph_mock.png" alt="knowledge graph mock">}}<br/>

Knowledge graphs are incredibly interesting. The graph can contain the "model service" and both implemented and proposed instances, resulting in the ability to check the data for type and fit on the graph, providing guard rails for the devices, so they will accept the data when it's eventually committed. The possibilities are limitless, but so is screen size. Just playing around a little, but here is a thrown-together example of data provenance for a simple service. Unlike traditional SNMP-based tooling, knowledge graphs are intended to be multidimensional, so you can query for physical topology, query for services, query for a full graph of information and validations that go into what a service is, including sourcing logs from each agent that actuates the changes and service tests, and dare I say it, in real time.

{{<imgcenterlink href="" src="fuzzy_projection.png" alt="Reference model and inputs">}}<br/>

# Am I me? What am I? Who should I be?

I'm not having a mental breakdown, or at least I don't think I am. I want to ask the question of you: what do you think should be in a knowledge graph? Is it desired state? Is it actual state? Is it operational state? I think it should be all of them. It should be the projection of desired state and the measurement between desired and actual, it should also include a federation of operational data, meaning some live data can live on the graph, but knowing where to find data is just as important as actually getting it. For example, instead of streaming a gNMI based gRPC telemetry feed to the graph, details of where to access it, what the data looks like and where to get the credentials is just as useful. Imagine being able to query state and metrics via one system, including direct device access, topological data, metrics, gRPC, whatever! No more fragmented control systems or multiple SPoGs. This goes beyond streaming database updates and provides a fully interactive communication experience.

Storing desired state on a graph is relatively simple and it's feasible to have just desired state knowledge and operate changes against a network. This video is from 2021 and features me (*jazz hands*) talking about knowledge graphs for a NANOG event. Whilst I was met by ferociously silent applause, it now lives as a historic marker and anchor for some of the research I was working through: https://nanog.org/news-stories/nanog-tv/nanog-81-webcast/navigating-automata/. In 2021 I had a desired-state graph, in which agents collect a Terraform provider from a file store, pull information from the graph, decide if they need to do anything, then execute changes when the trigger signals were received. A lot of work went into this, but the full data graph was available to query and inspect, as well as control. I could also export this data into JSON form and encode arbitrary JSON back into the graph with relationships. The graph edges are in themselves the relationship and the edges also contain encoded data. I've seen some recent examples (H2 2025) with [JSON-LD](https://json-ld.org/), which is a light JSON format for relational data, and it's great to see brains heading this way.

With some thought, you can also store the actual state, with federated links to the data stores, generated configs and even Git branches or history log UUIDs, enabling a full configuration-sourcing system. For real-time feedback, agent processes can place marker data on the graph such as last Git commit for the data, or a stream marker with logs. Dependent services can then use all of the data to measure, take state or current action from the knowledge graph and do something with it. With great power comes great responsibility, and with this level of visibility and control, it's important to safeguard access and do experiments on a dev system to ensure that you're not creating resonance and oscillations. Changes must always result in stable outcomes for both the underlying network and the knowledge graph itself.

# Back to basics

To move between desired state and actual state is a simple matter of taking the data from a knowledge graph, projecting it into the form a horizontal tool requires and executing upon it, and then assessing signals for signs of success. The result of this magic is your horizontal tool is just another cattle scenario. Create an environment, put the data in it, execute and discard. You might be racing ahead now and thinking this would also be great for triggering constantly executed service tests at the data-plane and control-plane level to ensure service consistency. This is the topic of service assurance, fuelled by meaningful input data. Some vendors refer to this as QoE, but when powered by a knowledge graph, we know what SHOULD be happening, instead of retrospectively building what IS happening and putting some measurements around it with accurately guessed parameters through AI or ML. Whilst a service of type X exists, run tests Y. Simple right.

For the keen mind, you could be thinking if all of this resembles a digital twin. Yes, it does, but it's multifaceted as ever. Whilst this system won't allow us to simulate a configuration-level acceptance change *([Forward Networks](https://www.forwardnetworks.com/) does this extremely well)*, our knowledge graph represents the culmination of current baseline state and service state. We can check for the shape of the graph data against the services, giving us a line of protection (synthesis), and then provide hooks for other systems like Forward Networks.

# Close

As with all exciting technology, do we actually need this? Is the extra overhead of building, using and maintaining it worth the effort? As networks grow in complexity, I think yes is the answer, but like all new technology, the equilibrium between usability and capabilities will find itself after going through the genesis phase. Knowledge graphs are in their infancy for the non-FAANGs, and so if you're just starting this journey, it's great to be aware, but don't panic, you're not behind either. Much like anything complicated, some time needs to pass so that the right value is found. For example, adding cost control to a knowledge graph sounds great, but will it ever be needed? I'm not sure. For cost-centre-based businesses, expenditure management is key, but it won't be for everyone.

Fully extensible knowledge graphs are what dreams are made of, but I fear the skill level required to utilise one would make it a job for skilled developers, typically professional services from a vendor offering such a thing.

This blog post is personal and raw. It's a brain dump of some thoughts and opinions, so it's here and not over at Curvium.com. I'll keep a close eye on all of this activity and as the technology continues to stabilise, will create a case study and demo for our customers.

Need something as simple as an extra pair of eyes, or network automation pathfinding session? Head over and reach out! > https://curvium.com